{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"F:\\\\Text audio dataset\\\\cleaned_data.csv\", names=['Text','Emotion'],skiprows=1)\n",
    "df_test = pd.read_csv(\"F:\\\\Text audio dataset\\\\cleaned_data_test.csv\", names=['Text','Emotion'], skiprows=1)\n",
    "df_val = pd.read_csv(\"F:\\\\Text audio dataset\\\\cleaned_data_val.csv\", names=['Text','Emotion'], skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Emotion\n",
      "0                              didnt feel humiliated  sadness\n",
      "1  go feeling hopeless damned hopeful around some...  sadness\n",
      "2          im grabbing minute post feel greedy wrong    anger\n",
      "3  ever feeling nostalgic fireplace know still pr...     love\n",
      "4                                    feeling grouchy    anger\n",
      "                                                Text  Emotion\n",
      "0        im feeling rather rotten im ambitious right  sadness\n",
      "1                       im updating blog feel shitty  sadness\n",
      "2    never make separate ever want feel like ashamed  sadness\n",
      "3  left bouquet red yellow tulip arm feeling slig...      joy\n",
      "4                            feeling little vain one  sadness\n",
      "                                                Text  Emotion\n",
      "0           im feeling quite sad sorry ill snap soon  sadness\n",
      "1  feel like still looking blank canvas blank pie...  sadness\n",
      "2                         feel like faithful servant     love\n",
      "3                                feeling cranky blue    anger\n",
      "4                              treat feeling festive      joy\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print(df_test.head())\n",
    "print(df_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15969, 2)\n",
      "(2000, 2)\n",
      "(1998, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(df_train['Emotion'])\n",
    "y_test = label_encoder.transform(df_test['Emotion'])\n",
    "y_val = label_encoder.transform(df_val['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_train = tfidf.fit_transform(df_train['Text'])\n",
    "tfidf_test = tfidf.transform(df_test['Text'])\n",
    "tfidf_val = tfidf.transform (df_val['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.871\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.836449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.898236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.707143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.912933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.660194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1 score\n",
       "sadness   0.857143\n",
       "anger     0.836449\n",
       "love      0.898236\n",
       "surprise  0.707143\n",
       "fear      0.912933\n",
       "joy       0.660194"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_LR = LogisticRegression()\n",
    "model_LR.fit(tfidf_train,y_train)\n",
    "\n",
    "y_pred = model_LR.predict(tfidf_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "f1 = f1_score(y_test,y_pred,average=None)\n",
    "pd.DataFrame(f1,index=df_train.Emotion.unique(),columns=['F1 score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86       275\n",
      "           1       0.88      0.80      0.84       224\n",
      "           2       0.85      0.95      0.90       695\n",
      "           3       0.82      0.62      0.71       159\n",
      "           4       0.90      0.93      0.91       581\n",
      "           5       0.92      0.52      0.66        66\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.87      0.77      0.81      2000\n",
      "weighted avg       0.87      0.87      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.880143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.814159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.768293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.898526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.601504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1 score\n",
       "sadness   0.880143\n",
       "anger     0.814159\n",
       "love      0.896000\n",
       "surprise  0.768293\n",
       "fear      0.898526\n",
       "joy       0.601504"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_DT = DecisionTreeClassifier()\n",
    "model_DT.fit(tfidf_train,y_train)\n",
    "\n",
    "y_pred = model_DT.predict(tfidf_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "f1 = f1_score(y_test,y_pred,average=None)\n",
    "pd.DataFrame(f1,index=df_train.Emotion.unique(),columns=['F1 score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       275\n",
      "           1       0.81      0.82      0.81       224\n",
      "           2       0.91      0.89      0.90       695\n",
      "           3       0.75      0.79      0.77       159\n",
      "           4       0.91      0.89      0.90       581\n",
      "           5       0.60      0.61      0.60        66\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.80      0.82      0.81      2000\n",
      "weighted avg       0.87      0.86      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8675\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.857685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.827907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.893645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.681648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.914821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.654206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1 score\n",
       "sadness   0.857685\n",
       "anger     0.827907\n",
       "love      0.893645\n",
       "surprise  0.681648\n",
       "fear      0.914821\n",
       "joy       0.654206"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model_SVC = SVC()\n",
    "model_SVC.fit(tfidf_train,y_train)\n",
    "\n",
    "y_pred = model_SVC.predict(tfidf_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "f1 = f1_score(y_test,y_pred,average=None)\n",
    "pd.DataFrame(f1,index=df_train.Emotion.unique(),columns=['F1 score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86       275\n",
      "           1       0.86      0.79      0.83       224\n",
      "           2       0.83      0.96      0.89       695\n",
      "           3       0.84      0.57      0.68       159\n",
      "           4       0.91      0.92      0.91       581\n",
      "           5       0.85      0.53      0.65        66\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.87      0.77      0.80      2000\n",
      "weighted avg       0.87      0.87      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.891697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.867841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.906294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.745763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.931364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.603448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1 score\n",
       "sadness   0.891697\n",
       "anger     0.867841\n",
       "love      0.906294\n",
       "surprise  0.745763\n",
       "fear      0.931364\n",
       "joy       0.603448"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_RFC = RandomForestClassifier()\n",
    "model_RFC.fit(tfidf_train,y_train)\n",
    "\n",
    "y_pred = model_RFC.predict(tfidf_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "f1 = f1_score(y_test,y_pred,average=None)\n",
    "pd.DataFrame(f1,index=df_train.Emotion.unique(),columns=['F1 score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89       275\n",
      "           1       0.86      0.88      0.87       224\n",
      "           2       0.88      0.93      0.91       695\n",
      "           3       0.81      0.69      0.75       159\n",
      "           4       0.94      0.92      0.93       581\n",
      "           5       0.70      0.53      0.60        66\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.85      0.81      0.82      2000\n",
      "weighted avg       0.88      0.89      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_tensor = torch.tensor(tfidf_train.toarray(), dtype=torch.float32)\n",
    "tfidf_test_tensor = torch.tensor(tfidf_test.toarray(), dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM expects input of shape (batch_size, seq_length, input_size)\n",
    "        x = x.unsqueeze(1)  # Add a sequence length dimension\n",
    "        _, (hn, _) = self.lstm(x)  # hn is the hidden state\n",
    "        out = self.fc(hn[-1])  # Fully connected layer takes the last hidden state\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(tfidf_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "input_size = tfidf_train_tensor.shape[1]  \n",
    "hidden_size = 512\n",
    "num_classes = len(label_encoder.classes_)\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.2218\n",
      "Epoch [2/10], Loss: 0.3941\n",
      "Epoch [3/10], Loss: 0.2378\n",
      "Epoch [4/10], Loss: 0.0931\n",
      "Epoch [5/10], Loss: 0.0550\n",
      "Epoch [6/10], Loss: 0.0293\n",
      "Epoch [7/10], Loss: 0.0450\n",
      "Epoch [8/10], Loss: 0.0223\n",
      "Epoch [9/10], Loss: 0.0054\n",
      "Epoch [10/10], Loss: 0.0103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.86      0.81      0.83       275\n",
      "        fear       0.83      0.80      0.82       224\n",
      "         joy       0.86      0.92      0.89       695\n",
      "        love       0.74      0.69      0.71       159\n",
      "     sadness       0.90      0.91      0.90       581\n",
      "    surprise       0.81      0.64      0.71        66\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.83      0.79      0.81      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(tfidf_test_tensor)\n",
    "    y_pred_classes = torch.argmax(y_pred, dim=1).numpy()\n",
    "    y_true = y_test_tensor.numpy()\n",
    "    print(classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
